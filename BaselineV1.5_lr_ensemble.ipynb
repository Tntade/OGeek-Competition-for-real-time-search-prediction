{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2099998, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['query_len']=data['query'].apply(lambda x:len(x.replace('{','').replace('}','').split(',')))\n",
    "# print(data[data['label']!=-1].groupby('query_len')['label'].mean())\n",
    "# print('====================')\n",
    "data['prefix_len']=data['prefix'].apply(lambda x:len(str(x)))\n",
    "# print(data[data['label']!=-1].groupby('prefix_len')['label'].mean())\n",
    "# print('====================')\n",
    "# data['tag_len']=data['tag'].apply(lambda x:len(str(x)))\n",
    "# print(data[data['label']!=-1].groupby('tag_len')['label'].mean())\n",
    "# print('====================')\n",
    "data['title_len']=data['title'].apply(lambda x:len(str(x)))\n",
    "# print(data[data['label']!=-1].groupby('title_len')['label'].mean())\n",
    "# print('====================')\n",
    "# print(data.shape)\n",
    "# print('====================')\n",
    "# print(data.columns)\n",
    "# print('====================')\n",
    "# print(data.describe())\n",
    "# print('====================')\n",
    "# print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "lr_col=['prefix','title','tag','query']\n",
    "for feature in lr_col:\n",
    "    data[feature]=data[feature].astype(str)\n",
    "\n",
    "data['prefix']=le.fit_transform(data['prefix'])\n",
    "data['title']=le.fit_transform(data['title'])\n",
    "data['query']=le.fit_transform(data['query'])\n",
    "data['tag']=le.fit_transform(data['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049998, 8)\n",
      "(50000, 8)\n"
     ]
    }
   ],
   "source": [
    "traindf=data[data['label']!=-1]\n",
    "testdf=data[data['label']==-1]\n",
    "print(traindf.shape)\n",
    "print(testdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=['prefix','query','title','tag','query_len','prefix_len','title_len']\n",
    "\n",
    "for item in col:\n",
    "    temp=traindf.groupby(item,as_index=False)['label'].agg({item+'_click':'sum',item+'_count':'count'})\n",
    "    temp[item+'_ctr']=(temp[item+'_click']/temp[item+'_count'])\n",
    "    traindf = pd.merge(traindf, temp, on=item, how='left')\n",
    "    testdf=pd.merge(testdf,temp,on=item,how='left')\n",
    "    #testdf中有很多是traindf中没有的，所以导致testdf.merger的时候就会出现很多NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(col)):\n",
    "    for j in range(i+1,len(col)):\n",
    "        item_g=[col[i],col[j]]\n",
    "        temp=traindf.groupby(item_g,as_index=False)['label'].agg({'_'.join(item_g)+'_click':'sum','_'.join(item_g)+'_count':'count'})\n",
    "        temp['_'.join(item_g)+'_ctr']=temp['_'.join(item_g)+'_click']/(temp['_'.join(item_g)+'_count']+3)\n",
    "        traindf=pd.merge(traindf,temp,on=item_g,how='left')\n",
    "        testdf=pd.merge(testdf,temp,on=item_g,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049998, 92) (50000, 92)\n"
     ]
    }
   ],
   "source": [
    "print(traindf.shape,testdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===========Train==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traindf.to_csv('../data/final_train2.csv',index=False)\n",
    "testddf=testdf.drop(['label'],axis=1)\n",
    "# testddf.to_csv('../data/final_test2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=traindf.pop('label').values\n",
    "X=traindf.as_matrix()\n",
    "testX=testddf.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train=pd.DataFrame()\n",
    "sub_test=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "losstrain=0\n",
    "lossval=0\n",
    "fs=0\n",
    "ft=0\n",
    "\n",
    "N=10\n",
    "\n",
    "skf=StratifiedKFold(n_splits=N,random_state=1,shuffle=True)\n",
    "\n",
    "clf= LGBMClassifier(boosting_type='gbdt', num_leaves=60, max_depth=-1, \n",
    "                         learning_rate=0.05, n_estimators=2000,objective='binary', \n",
    "                         min_split_gain=0,min_child_weight=5, min_child_samples=10, \n",
    "                         subsample=0.8, subsample_freq=1,colsample_bytree=0.8, \n",
    "                         reg_alpha=3, reg_lambda=5, random_state=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold=0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.336964\tvalid's binary_logloss: 0.337109\n",
      "[100]\ttrain's binary_logloss: 0.322936\tvalid's binary_logloss: 0.323395\n",
      "[150]\ttrain's binary_logloss: 0.321467\tvalid's binary_logloss: 0.322248\n",
      "[200]\ttrain's binary_logloss: 0.321086\tvalid's binary_logloss: 0.322239\n",
      "[250]\ttrain's binary_logloss: 0.320886\tvalid's binary_logloss: 0.322464\n",
      "Early stopping, best iteration is:\n",
      "[170]\ttrain's binary_logloss: 0.321267\tvalid's binary_logloss: 0.322185\n",
      "best logloss on train_set: 0.3212672203670879\n",
      "best logloss on test_set: 0.32218456552549257\n",
      "f1_score on train_set: 0.8009451469807038\n",
      "f1_score on test_set: 0.7995975305268127\n",
      "Fold=1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.337016\tvalid's binary_logloss: 0.336467\n",
      "[100]\ttrain's binary_logloss: 0.323057\tvalid's binary_logloss: 0.322658\n",
      "[150]\ttrain's binary_logloss: 0.321575\tvalid's binary_logloss: 0.321448\n",
      "[200]\ttrain's binary_logloss: 0.321191\tvalid's binary_logloss: 0.321422\n",
      "[250]\ttrain's binary_logloss: 0.320997\tvalid's binary_logloss: 0.321607\n",
      "Early stopping, best iteration is:\n",
      "[175]\ttrain's binary_logloss: 0.321337\tvalid's binary_logloss: 0.321385\n",
      "best logloss on train_set: 0.32133738808224027\n",
      "best logloss on test_set: 0.3213854406940395\n",
      "f1_score on train_set: 0.8007705995960633\n",
      "f1_score on test_set: 0.8015572900173239\n",
      "Fold=2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.337031\tvalid's binary_logloss: 0.336376\n",
      "[100]\ttrain's binary_logloss: 0.32305\tvalid's binary_logloss: 0.322539\n",
      "[150]\ttrain's binary_logloss: 0.321567\tvalid's binary_logloss: 0.321401\n",
      "[200]\ttrain's binary_logloss: 0.321195\tvalid's binary_logloss: 0.321438\n",
      "[250]\ttrain's binary_logloss: 0.320983\tvalid's binary_logloss: 0.321638\n",
      "Early stopping, best iteration is:\n",
      "[173]\ttrain's binary_logloss: 0.321342\tvalid's binary_logloss: 0.321352\n",
      "best logloss on train_set: 0.3213421065627861\n",
      "best logloss on test_set: 0.3213521909649771\n",
      "f1_score on train_set: 0.8009666684383859\n",
      "f1_score on test_set: 0.800178650075368\n",
      "Fold=3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.336864\tvalid's binary_logloss: 0.338086\n",
      "[100]\ttrain's binary_logloss: 0.322864\tvalid's binary_logloss: 0.324509\n",
      "[150]\ttrain's binary_logloss: 0.321377\tvalid's binary_logloss: 0.323357\n",
      "[200]\ttrain's binary_logloss: 0.320995\tvalid's binary_logloss: 0.323358\n",
      "[250]\ttrain's binary_logloss: 0.320787\tvalid's binary_logloss: 0.323573\n",
      "Early stopping, best iteration is:\n",
      "[169]\ttrain's binary_logloss: 0.321187\tvalid's binary_logloss: 0.323299\n",
      "best logloss on train_set: 0.32118736484824356\n",
      "best logloss on test_set: 0.32329874649344403\n",
      "f1_score on train_set: 0.8010183056173167\n",
      "f1_score on test_set: 0.7997911058334939\n",
      "Fold=4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.336754\tvalid's binary_logloss: 0.338931\n",
      "[100]\ttrain's binary_logloss: 0.322746\tvalid's binary_logloss: 0.325268\n",
      "[150]\ttrain's binary_logloss: 0.321261\tvalid's binary_logloss: 0.324065\n",
      "[200]\ttrain's binary_logloss: 0.320894\tvalid's binary_logloss: 0.324068\n",
      "[250]\ttrain's binary_logloss: 0.320691\tvalid's binary_logloss: 0.324274\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttrain's binary_logloss: 0.321098\tvalid's binary_logloss: 0.324005\n",
      "best logloss on train_set: 0.3210982136329796\n",
      "best logloss on test_set: 0.32400450249891105\n",
      "f1_score on train_set: 0.8010336951772625\n",
      "f1_score on test_set: 0.7994908097367114\n",
      "Fold=5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.336811\tvalid's binary_logloss: 0.338311\n",
      "[100]\ttrain's binary_logloss: 0.322788\tvalid's binary_logloss: 0.324783\n",
      "[150]\ttrain's binary_logloss: 0.321318\tvalid's binary_logloss: 0.323702\n",
      "[200]\ttrain's binary_logloss: 0.320924\tvalid's binary_logloss: 0.323714\n",
      "[250]\ttrain's binary_logloss: 0.320709\tvalid's binary_logloss: 0.323921\n",
      "Early stopping, best iteration is:\n",
      "[168]\ttrain's binary_logloss: 0.321127\tvalid's binary_logloss: 0.323655\n",
      "best logloss on train_set: 0.3211267750068811\n",
      "best logloss on test_set: 0.3236546811976009\n",
      "f1_score on train_set: 0.8009940157601998\n",
      "f1_score on test_set: 0.7995202853432258\n",
      "Fold=6\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.337133\tvalid's binary_logloss: 0.336122\n",
      "[100]\ttrain's binary_logloss: 0.323115\tvalid's binary_logloss: 0.322169\n",
      "[150]\ttrain's binary_logloss: 0.321625\tvalid's binary_logloss: 0.321012\n",
      "[200]\ttrain's binary_logloss: 0.321238\tvalid's binary_logloss: 0.32103\n",
      "[250]\ttrain's binary_logloss: 0.321023\tvalid's binary_logloss: 0.321243\n",
      "Early stopping, best iteration is:\n",
      "[171]\ttrain's binary_logloss: 0.321419\tvalid's binary_logloss: 0.32097\n",
      "best logloss on train_set: 0.3214192068966767\n",
      "best logloss on test_set: 0.32096966196211324\n",
      "f1_score on train_set: 0.8006715239218323\n",
      "f1_score on test_set: 0.8025109902391775\n",
      "Fold=7\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.336851\tvalid's binary_logloss: 0.338285\n",
      "[100]\ttrain's binary_logloss: 0.322813\tvalid's binary_logloss: 0.324698\n",
      "[150]\ttrain's binary_logloss: 0.321332\tvalid's binary_logloss: 0.323553\n",
      "[200]\ttrain's binary_logloss: 0.320953\tvalid's binary_logloss: 0.323551\n",
      "[250]\ttrain's binary_logloss: 0.320745\tvalid's binary_logloss: 0.323779\n",
      "Early stopping, best iteration is:\n",
      "[171]\ttrain's binary_logloss: 0.321132\tvalid's binary_logloss: 0.323495\n",
      "best logloss on train_set: 0.3211317382474884\n",
      "best logloss on test_set: 0.32349528710038045\n",
      "f1_score on train_set: 0.8010819145110852\n",
      "f1_score on test_set: 0.7989141238445483\n",
      "Fold=8\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.337111\tvalid's binary_logloss: 0.336238\n",
      "[100]\ttrain's binary_logloss: 0.323104\tvalid's binary_logloss: 0.322308\n",
      "[150]\ttrain's binary_logloss: 0.321644\tvalid's binary_logloss: 0.321124\n",
      "[200]\ttrain's binary_logloss: 0.321269\tvalid's binary_logloss: 0.321129\n",
      "[250]\ttrain's binary_logloss: 0.321066\tvalid's binary_logloss: 0.321324\n",
      "Early stopping, best iteration is:\n",
      "[181]\ttrain's binary_logloss: 0.321356\tvalid's binary_logloss: 0.321054\n",
      "best logloss on train_set: 0.3213560802253669\n",
      "best logloss on test_set: 0.32105356542490066\n",
      "f1_score on train_set: 0.8008972888702625\n",
      "f1_score on test_set: 0.8006311813528155\n",
      "Fold=9\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.336914\tvalid's binary_logloss: 0.337333\n",
      "[100]\ttrain's binary_logloss: 0.32289\tvalid's binary_logloss: 0.323624\n",
      "[150]\ttrain's binary_logloss: 0.32142\tvalid's binary_logloss: 0.322513\n",
      "[200]\ttrain's binary_logloss: 0.321041\tvalid's binary_logloss: 0.322527\n",
      "[250]\ttrain's binary_logloss: 0.320855\tvalid's binary_logloss: 0.322759\n",
      "Early stopping, best iteration is:\n",
      "[168]\ttrain's binary_logloss: 0.321249\tvalid's binary_logloss: 0.322479\n",
      "best logloss on train_set: 0.32124923088354607\n",
      "best logloss on test_set: 0.3224786115144472\n",
      "f1_score on train_set: 0.8009119138941251\n",
      "f1_score on test_set: 0.8005865284845323\n",
      "mean logloss in train set：0.32125\n",
      "mean logloss in test set：0.32239\n",
      "mean f1 in train set：0.80093\n",
      "mean f1 in test set：0.80028\n"
     ]
    }
   ],
   "source": [
    "for i,(train_index,test_index) in enumerate(skf.split(X,y)):\n",
    "    print(\"Fold=%s\"%(i))\n",
    "    model=clf.fit(X[train_index],y[train_index],\n",
    "                 eval_names=['train','valid'],\n",
    "                 eval_metric='logloss',\n",
    "                  eval_set=[(X[train_index],y[train_index]),(X[test_index],y[test_index])],\n",
    "                 early_stopping_rounds=100,\n",
    "                  verbose=50,)\n",
    "    \n",
    "    trainss=model.best_score_['train']['binary_logloss']\n",
    "    valss=model.best_score_['valid']['binary_logloss']\n",
    "    losstrain+=trainss\n",
    "    lossval+=valss\n",
    "    print(\"best logloss on train_set:\",trainss)\n",
    "    print(\"best logloss on test_set:\",valss)\n",
    "    \n",
    "    train_proba=model.predict_proba(X[train_index],num_iteration=model.best_iteration_)[:,1]\n",
    "    train_pred=np.where(train_proba>0.37,1,0)\n",
    "    ftrain=f1_score(y[train_index],train_pred)\n",
    "    print(\"f1_score on train_set:\",ftrain)\n",
    "    ft+=ftrain\n",
    "    \n",
    "    val_proba=model.predict_proba(X[test_index],num_iteration=model.best_iteration_)[:,1]\n",
    "    val_pred=np.where(val_proba>0.37,1,0)\n",
    "    fval=f1_score(y[test_index],val_pred)\n",
    "    print(\"f1_score on test_set:\",fval)\n",
    "    fs+=fval\n",
    "    \n",
    "    train_all=model.predict_proba(X,num_iteration=model.best_iteration_)[:,1]\n",
    "    sub_train['ans_%s'%str(i)]=train_all\n",
    "    test_proba=model.predict_proba(testX,num_iteration=model.best_iteration_)[:,1]\n",
    "    sub_test['ans_%s'%str(i)]=test_proba\n",
    "print(\"mean logloss in train set：%.5f\"%(losstrain/N))\n",
    "print(\"mean logloss in test set：%.5f\"%(lossval/N))\n",
    "print(\"mean f1 in train set：%.5f\"%(ft/N))\n",
    "print(\"mean f1 in test set：%.5f\"%(fs/N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train['label']=0\n",
    "for i in range(N):\n",
    "    sub_train['label']+=sub_train['ans_%s'%str(i)]\n",
    "sub_train['label']=sub_train['label']/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test['label']=0\n",
    "for i in range(N):\n",
    "    sub_test['label']+=sub_test['ans_%s'%str(i)]\n",
    "sub_test['label']=sub_test['label']/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049998, 11)\n"
     ]
    }
   ],
   "source": [
    "print(sub_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 11)\n"
     ]
    }
   ],
   "source": [
    "print(sub_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train['label'].to_csv('../data/ensemble/lgb_train.csv',index=True)\n",
    "sub_test['label'].to_csv('../data/ensemble/lgb_test.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============ensemble==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "gc.collect()\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train=pd.read_csv('../data/ensemble/lgb_train.csv', names= ['lgb_label'], header= None)\n",
    "lgb_test=pd.read_csv('../data/ensemble/lgb_test.csv',names= ['lgb_label'], header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train=pd.read_csv('../data/ensemble/lr_trainn.csv')\n",
    "lr_train.columns=['index','lr_label']\n",
    "lr_test=pd.read_csv('../data/ensemble/lr_testt.csv')\n",
    "lr_test.columns=['index','lr_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049998, 1) (50000, 1) (2049998, 2) (50000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(lgb_train.shape,lgb_test.shape,lr_train.shape,lr_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train=lr_train.drop(['index'],axis=1)\n",
    "lr_test=lr_test.drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049998, 3)\n",
      "Index(['lgb_label', 'lr_label', 'label'], dtype='object')\n",
      "0    1287218\n",
      "1     762780\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ntrain=pd.concat([lgb_train,lr_train],axis=1)\n",
    "ntrain['label']=data['label'][data['label']!=-1]\n",
    "print(ntrain.shape)\n",
    "print(ntrain.columns)\n",
    "print(ntrain['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3720881678908955\n"
     ]
    }
   ],
   "source": [
    "print(762780/2049998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n",
      "Index(['lgb_label', 'lr_label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ntest=pd.concat([lgb_test,lr_test],axis=1)\n",
    "print(ntest.shape)\n",
    "print(ntest.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt=0\n",
    "lv=0\n",
    "fin=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=ntrain.pop('label').values\n",
    "x=ntrain.as_matrix()\n",
    "testx=ntest.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=10\n",
    "skf=StratifiedKFold(n_splits=M,random_state=1,shuffle=True)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression(penalty='l2', dual=False, tol=0.001, C=1, random_state=1,\n",
    "                            solver='liblinear', max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold=0\n",
      "[LibLinear]f1 score on train set:0.80092\n",
      "f1 score on val set:0.80070\n",
      "Fold=1\n",
      "[LibLinear]f1 score on train set:0.80074\n",
      "f1 score on val set:0.80216\n",
      "Fold=2\n",
      "[LibLinear]f1 score on train set:0.80100\n",
      "f1 score on val set:0.79993\n",
      "Fold=3\n",
      "[LibLinear]f1 score on train set:0.80100\n",
      "f1 score on val set:0.80006\n",
      "Fold=4\n",
      "[LibLinear]f1 score on train set:0.80093\n",
      "f1 score on val set:0.80031\n",
      "Fold=5\n",
      "[LibLinear]f1 score on train set:0.80101\n",
      "f1 score on val set:0.79983\n",
      "Fold=6\n",
      "[LibLinear]f1 score on train set:0.80066\n",
      "f1 score on val set:0.80288\n",
      "Fold=7\n",
      "[LibLinear]f1 score on train set:0.80096\n",
      "f1 score on val set:0.80021\n",
      "Fold=8\n",
      "[LibLinear]f1 score on train set:0.80088\n",
      "f1 score on val set:0.80120\n",
      "Fold=9\n",
      "[LibLinear]f1 score on train set:0.80078\n",
      "f1 score on val set:0.80167\n"
     ]
    }
   ],
   "source": [
    "for i,(train_index,test_index) in enumerate(skf.split(x,Y)):\n",
    "    print(\"Fold=%s\"%str(i))\n",
    "    clf.fit(x[train_index],Y[train_index])\n",
    "    \n",
    "    ytrain=clf.predict_proba(x[train_index])[:,1]\n",
    "    ft=f1_score(Y[train_index],np.where(ytrain>0.37,1,0))\n",
    "    print('f1 score on train set:%.5f'%ft)\n",
    "    \n",
    "    yval=clf.predict_proba(x[test_index])[:,1]\n",
    "    fv=f1_score(Y[test_index],np.where(yval>0.37,1,0))\n",
    "    print('f1 score on val set:%.5f'%fv)\n",
    "    \n",
    "    ytest=clf.predict_proba(testx)[:,1]\n",
    "    fin['ans_%s'%str(i)]=ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin['label']=0\n",
    "for i in range(M):\n",
    "    fin['label']+=fin['ans_%s'%str(i)]\n",
    "fin['label']=fin['label']/M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    33224\n",
      "1    16776\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "fin['label']=fin['label'].apply(lambda x:np.where(x>0.37,1,0))\n",
    "print(fin['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33552\n"
     ]
    }
   ],
   "source": [
    "print(16776/50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin['label'].to_csv('../data/BaselineV1_4.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============Weighting==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntest['nlabel']=ntest['lgb_label']*2+ntest['lr_label']*1\n",
    "ntest['nlabel']=ntest['nlabel']/3\n",
    "ntest['nlabel']=ntest['nlabel'].apply(lambda x:np.where(x>0.37,1,0))\n",
    "print(ntest['nlabel'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(17800/50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntest['nlabel'].to_csv('../data/BaselineV1_42.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100/2971==0.7924"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
