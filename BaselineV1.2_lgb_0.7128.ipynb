{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>2018/11/2<br>调节了temp[item+'_ctr']中的细节，即将traindf中与testdf相同的item的_click,_count,_ctr赋值给testdf中，而不是直接使用testdf['label']=-1进行ctr计算<font>  \n",
    "### 之前用了data.groupby()的成绩为0.6231，非常的差！过拟合现象非常严重！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2099998, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['query_len']=data['query'].apply(lambda x:len(x.replace('{','').replace('}','').split(',')))\n",
    "# print(data[data['label']!=-1].groupby('query_len')['label'].mean())\n",
    "# print('====================')\n",
    "data['prefix_len']=data['prefix'].apply(lambda x:len(str(x)))\n",
    "# print(data[data['label']!=-1].groupby('prefix_len')['label'].mean())\n",
    "# print('====================')\n",
    "data['tag_len']=data['tag'].apply(lambda x:len(str(x)))\n",
    "# print(data[data['label']!=-1].groupby('tag_len')['label'].mean())\n",
    "# print('====================')\n",
    "data['title_len']=data['title'].apply(lambda x:len(str(x)))\n",
    "# print(data[data['label']!=-1].groupby('title_len')['label'].mean())\n",
    "# print('====================')\n",
    "# print(data.shape)\n",
    "# print('====================')\n",
    "# print(data.columns)\n",
    "# print('====================')\n",
    "# print(data.describe())\n",
    "# print('====================')\n",
    "# print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "lr_col=['prefix','title','tag','query']\n",
    "for feature in lr_col:\n",
    "    data[feature]=data[feature].astype(str)\n",
    "\n",
    "data['prefix']=le.fit_transform(data['prefix'])\n",
    "data['title']=le.fit_transform(data['title'])\n",
    "data['query']=le.fit_transform(data['query'])\n",
    "data['tag']=le.fit_transform(data['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049998, 9)\n",
      "(50000, 9)\n"
     ]
    }
   ],
   "source": [
    "traindf=data[data['label']!=-1] #有一个标签是音乐,可以直接删除这个样本\n",
    "testdf=data[data['label']==-1]\n",
    "print(traindf.shape)\n",
    "print(testdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#单项历史点击率特征构造\n",
    "col=['prefix','query','title','tag','query_len','prefix_len','tag_len','title_len']\n",
    "for item in col:\n",
    "    temp=traindf.groupby(item,as_index=False)['label'].agg({item+'_click':'sum',item+'_count':'count'})\n",
    "    temp[item+'_ctr']=(temp[item+'_click']/temp[item+'_count'])\n",
    "    traindf = pd.merge(traindf, temp, on=item, how='left')\n",
    "    testdf=pd.merge(testdf,temp,on=item,how='left')\n",
    "    #testdf中有很多是traindf中没有的，所以导致testdf.merger的时候就会出现很多NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#交叉特征历史点击率特征构造\n",
    "cols=['prefix','query','title','tag','query_len','title_len']\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i+1,len(cols)):\n",
    "        item_g=[cols[i],cols[j]]\n",
    "        temp=traindf.groupby(item_g,as_index=False)['label'].agg({'_'.join(item_g)+'_click':'sum','_'.join(item_g)+'_count':'count'})\n",
    "        temp['_'.join(item_g)+'_ctr']=temp['_'.join(item_g)+'_click']/(temp['_'.join(item_g)+'_count']+3)\n",
    "        traindf=pd.merge(traindf,temp,on=item_g,how='left')\n",
    "        testdf=pd.merge(testdf,temp,on=item_g,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049998, 78) (50000, 78)\n"
     ]
    }
   ],
   "source": [
    "print(traindf.shape,testdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix                       0\n",
      "query                        0\n",
      "title                        0\n",
      "tag                          0\n",
      "label                        0\n",
      "query_len                    0\n",
      "prefix_len                   0\n",
      "tag_len                      0\n",
      "title_len                    0\n",
      "prefix_click                 0\n",
      "prefix_count                 0\n",
      "prefix_ctr                   0\n",
      "query_click                  0\n",
      "query_count                  0\n",
      "query_ctr                    0\n",
      "title_click                  0\n",
      "title_count                  0\n",
      "title_ctr                    0\n",
      "tag_click                    0\n",
      "tag_count                    0\n",
      "tag_ctr                      0\n",
      "query_len_click              0\n",
      "query_len_count              0\n",
      "query_len_ctr                0\n",
      "prefix_len_click             0\n",
      "prefix_len_count             0\n",
      "prefix_len_ctr               0\n",
      "tag_len_click                0\n",
      "tag_len_count                0\n",
      "tag_len_ctr                  0\n",
      "                            ..\n",
      "query_title_click            0\n",
      "query_title_count            0\n",
      "query_title_ctr              0\n",
      "query_tag_click              0\n",
      "query_tag_count              0\n",
      "query_tag_ctr                0\n",
      "query_query_len_click        0\n",
      "query_query_len_count        0\n",
      "query_query_len_ctr          0\n",
      "query_title_len_click        0\n",
      "query_title_len_count        0\n",
      "query_title_len_ctr          0\n",
      "title_tag_click              0\n",
      "title_tag_count              0\n",
      "title_tag_ctr                0\n",
      "title_query_len_click        0\n",
      "title_query_len_count        0\n",
      "title_query_len_ctr          0\n",
      "title_title_len_click        0\n",
      "title_title_len_count        0\n",
      "title_title_len_ctr          0\n",
      "tag_query_len_click          0\n",
      "tag_query_len_count          0\n",
      "tag_query_len_ctr            0\n",
      "tag_title_len_click          0\n",
      "tag_title_len_count          0\n",
      "tag_title_len_ctr            0\n",
      "query_len_title_len_click    0\n",
      "query_len_title_len_count    0\n",
      "query_len_title_len_ctr      0\n",
      "Length: 78, dtype: int64\n",
      "================\n",
      "prefix                          0\n",
      "query                           0\n",
      "title                           0\n",
      "tag                             0\n",
      "label                           0\n",
      "query_len                       0\n",
      "prefix_len                      0\n",
      "tag_len                         0\n",
      "title_len                       0\n",
      "prefix_click                 4399\n",
      "prefix_count                 4399\n",
      "prefix_ctr                   4399\n",
      "query_click                  4318\n",
      "query_count                  4318\n",
      "query_ctr                    4318\n",
      "title_click                  4063\n",
      "title_count                  4063\n",
      "title_ctr                    4063\n",
      "tag_click                       0\n",
      "tag_count                       0\n",
      "tag_ctr                         0\n",
      "query_len_click                 1\n",
      "query_len_count                 1\n",
      "query_len_ctr                   1\n",
      "prefix_len_click                0\n",
      "prefix_len_count                0\n",
      "prefix_len_ctr                  0\n",
      "tag_len_click                   0\n",
      "tag_len_count                   0\n",
      "tag_len_ctr                     0\n",
      "                             ... \n",
      "query_title_click            6869\n",
      "query_title_count            6869\n",
      "query_title_ctr              6869\n",
      "query_tag_click              6000\n",
      "query_tag_count              6000\n",
      "query_tag_ctr                6000\n",
      "query_query_len_click        4318\n",
      "query_query_len_count        4318\n",
      "query_query_len_ctr          4318\n",
      "query_title_len_click        6442\n",
      "query_title_len_count        6442\n",
      "query_title_len_ctr          6442\n",
      "title_tag_click              4282\n",
      "title_tag_count              4282\n",
      "title_tag_ctr                4282\n",
      "title_query_len_click        4702\n",
      "title_query_len_count        4702\n",
      "title_query_len_ctr          4702\n",
      "title_title_len_click        4063\n",
      "title_title_len_count        4063\n",
      "title_title_len_ctr          4063\n",
      "tag_query_len_click             1\n",
      "tag_query_len_count             1\n",
      "tag_query_len_ctr               1\n",
      "tag_title_len_click             2\n",
      "tag_title_len_count             2\n",
      "tag_title_len_ctr               2\n",
      "query_len_title_len_click       1\n",
      "query_len_title_len_count       1\n",
      "query_len_title_len_ctr         1\n",
      "Length: 78, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.isnull(traindf).sum())\n",
    "print(\"================\")\n",
    "print(pd.isnull(testdf).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===========Train==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traindf['id']=0\n",
    "# for i in range(traindf.shape[0]):\n",
    "#     traindf['id'][i]=i\n",
    "\n",
    "# nid=2000000\n",
    "# testdf['id']=0\n",
    "# for i in range(testdf.shape[0]):\n",
    "#     testdf['id'][i]=i+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traindf.to_csv('../data/final_train2.csv',index=False)\n",
    "testddf=testdf.drop(['label'],axis=1)\n",
    "# testddf.to_csv('../data/final_test2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=traindf.pop('label').values\n",
    "X=traindf.as_matrix()\n",
    "testX=testddf.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.05, random_state=1,\n",
    "#                             solver='liblinear', max_iter=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lr_fit(lr):\n",
    "#     fs=0 #f1_score\n",
    "#     mm=MinMaxScaler()\n",
    "#     X=mm.fit_transform(X)\n",
    "#     testX=mm.transform(testX)\n",
    "#     for i,(train_index,test_index) in enumerate(skf.split(X,y)):\n",
    "#         print('Fold:%s'%i)\n",
    "#         lr.fit(X[train_index],y[trin_index])\n",
    "#         y_pred=lr.predict(X[test_index])\n",
    "        \n",
    "#         fscore=f1_score(y[test_index],y_pred)\n",
    "#         fs+=fscore\n",
    "#         print(\"f1_score为：%.5f\"%fscore)\n",
    "        \n",
    "#         X_pred=lr.predict_proba(X[train_index])  #10折后得到一个完整的traindf_feature\n",
    "#         t_pred=lr.predict_proba(testX)  #10折后得到10个完整的testdf_feature,再对其取平均     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logloss=[]\n",
    "losstrain=0\n",
    "lossval=0\n",
    "fs=0\n",
    "\n",
    "N=10\n",
    "#基本kfold和StratifiedKfold基本相同，唯一不同的是skf可以保证在训练集、测试集中的采样的类别比例相同\n",
    "skf=StratifiedKFold(n_splits=N,random_state=1,shuffle=True)\n",
    "\n",
    "clf= LGBMClassifier(boosting_type='gbdt', num_leaves=60, max_depth=-1, \n",
    "                         learning_rate=0.05, n_estimators=2000,objective='binary', \n",
    "                         min_split_gain=0,min_child_weight=5, min_child_samples=10, \n",
    "                         subsample=0.8, subsample_freq=1,colsample_bytree=0.8, \n",
    "                         reg_alpha=3, reg_lambda=5, random_state=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold=0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.336972\tvalid's binary_logloss: 0.337136\n",
      "[100]\ttrain's binary_logloss: 0.32292\tvalid's binary_logloss: 0.323389\n",
      "[150]\ttrain's binary_logloss: 0.321464\tvalid's binary_logloss: 0.322258\n",
      "[200]\ttrain's binary_logloss: 0.321071\tvalid's binary_logloss: 0.322247\n",
      "[250]\ttrain's binary_logloss: 0.320882\tvalid's binary_logloss: 0.322456\n",
      "Early stopping, best iteration is:\n",
      "[178]\ttrain's binary_logloss: 0.32121\tvalid's binary_logloss: 0.322213\n",
      "best logloss on train_set: 0.321209729425755\n",
      "best logloss on test_set: 0.32221322634427024\n",
      "f1_score on test_set: 0.7940166549505219\n",
      "Fold=1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.337043\tvalid's binary_logloss: 0.336534\n",
      "[100]\ttrain's binary_logloss: 0.323041\tvalid's binary_logloss: 0.322684\n",
      "[150]\ttrain's binary_logloss: 0.32156\tvalid's binary_logloss: 0.321462\n",
      "[200]\ttrain's binary_logloss: 0.321189\tvalid's binary_logloss: 0.321429\n",
      "[250]\ttrain's binary_logloss: 0.32099\tvalid's binary_logloss: 0.321617\n",
      "Early stopping, best iteration is:\n",
      "[180]\ttrain's binary_logloss: 0.321305\tvalid's binary_logloss: 0.321398\n",
      "best logloss on train_set: 0.3213052319750222\n",
      "best logloss on test_set: 0.3213976943478539\n",
      "f1_score on test_set: 0.794900206748375\n",
      "Fold=2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.337063\tvalid's binary_logloss: 0.336417\n",
      "[100]\ttrain's binary_logloss: 0.323076\tvalid's binary_logloss: 0.322545\n",
      "[150]\ttrain's binary_logloss: 0.321606\tvalid's binary_logloss: 0.321408\n",
      "[200]\ttrain's binary_logloss: 0.321221\tvalid's binary_logloss: 0.321401\n",
      "[250]\ttrain's binary_logloss: 0.321017\tvalid's binary_logloss: 0.321596\n",
      "Early stopping, best iteration is:\n",
      "[173]\ttrain's binary_logloss: 0.321372\tvalid's binary_logloss: 0.321343\n",
      "best logloss on train_set: 0.3213723659691236\n",
      "best logloss on test_set: 0.3213431555154667\n",
      "f1_score on test_set: 0.7937059405740602\n",
      "Fold=3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.336871\tvalid's binary_logloss: 0.338052\n",
      "[100]\ttrain's binary_logloss: 0.322856\tvalid's binary_logloss: 0.324459\n",
      "[150]\ttrain's binary_logloss: 0.321365\tvalid's binary_logloss: 0.323307\n",
      "[200]\ttrain's binary_logloss: 0.320975\tvalid's binary_logloss: 0.323287\n",
      "[250]\ttrain's binary_logloss: 0.320773\tvalid's binary_logloss: 0.323494\n",
      "Early stopping, best iteration is:\n",
      "[177]\ttrain's binary_logloss: 0.321117\tvalid's binary_logloss: 0.323247\n",
      "best logloss on train_set: 0.3211167058793292\n",
      "best logloss on test_set: 0.3232473944287555\n",
      "f1_score on test_set: 0.7933667962003454\n",
      "Fold=4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.336814\tvalid's binary_logloss: 0.339041\n",
      "[100]\ttrain's binary_logloss: 0.322759\tvalid's binary_logloss: 0.32533\n",
      "[150]\ttrain's binary_logloss: 0.32128\tvalid's binary_logloss: 0.324118\n",
      "[200]\ttrain's binary_logloss: 0.320894\tvalid's binary_logloss: 0.324092\n",
      "[250]\ttrain's binary_logloss: 0.320687\tvalid's binary_logloss: 0.324267\n",
      "Early stopping, best iteration is:\n",
      "[172]\ttrain's binary_logloss: 0.321068\tvalid's binary_logloss: 0.324061\n",
      "best logloss on train_set: 0.32106807101247437\n",
      "best logloss on test_set: 0.32406118018440755\n",
      "f1_score on test_set: 0.7921931148361948\n",
      "Fold=5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.336851\tvalid's binary_logloss: 0.338335\n",
      "[100]\ttrain's binary_logloss: 0.322793\tvalid's binary_logloss: 0.324775\n",
      "[150]\ttrain's binary_logloss: 0.321309\tvalid's binary_logloss: 0.32369\n",
      "[200]\ttrain's binary_logloss: 0.320917\tvalid's binary_logloss: 0.323708\n",
      "[250]\ttrain's binary_logloss: 0.32071\tvalid's binary_logloss: 0.32391\n",
      "Early stopping, best iteration is:\n",
      "[177]\ttrain's binary_logloss: 0.321056\tvalid's binary_logloss: 0.323651\n",
      "best logloss on train_set: 0.32105565720012064\n",
      "best logloss on test_set: 0.3236506449145604\n",
      "f1_score on test_set: 0.7930427958705977\n",
      "Fold=6\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.337156\tvalid's binary_logloss: 0.336107\n",
      "[100]\ttrain's binary_logloss: 0.323118\tvalid's binary_logloss: 0.322129\n",
      "[150]\ttrain's binary_logloss: 0.321664\tvalid's binary_logloss: 0.320995\n",
      "[200]\ttrain's binary_logloss: 0.32127\tvalid's binary_logloss: 0.320988\n",
      "[250]\ttrain's binary_logloss: 0.321048\tvalid's binary_logloss: 0.321156\n",
      "Early stopping, best iteration is:\n",
      "[172]\ttrain's binary_logloss: 0.321448\tvalid's binary_logloss: 0.320946\n",
      "best logloss on train_set: 0.32144767212309244\n",
      "best logloss on test_set: 0.3209463471171974\n",
      "f1_score on test_set: 0.795039614192215\n",
      "Fold=7\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.336875\tvalid's binary_logloss: 0.338253\n",
      "[100]\ttrain's binary_logloss: 0.32282\tvalid's binary_logloss: 0.324646\n",
      "[150]\ttrain's binary_logloss: 0.321347\tvalid's binary_logloss: 0.323504\n",
      "[200]\ttrain's binary_logloss: 0.320947\tvalid's binary_logloss: 0.323468\n",
      "[250]\ttrain's binary_logloss: 0.320744\tvalid's binary_logloss: 0.323679\n",
      "Early stopping, best iteration is:\n",
      "[188]\ttrain's binary_logloss: 0.321007\tvalid's binary_logloss: 0.323436\n",
      "best logloss on train_set: 0.32100681511569373\n",
      "best logloss on test_set: 0.32343558285544727\n",
      "f1_score on test_set: 0.7931372217906717\n",
      "Fold=8\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.33709\tvalid's binary_logloss: 0.336245\n",
      "[100]\ttrain's binary_logloss: 0.323091\tvalid's binary_logloss: 0.322309\n",
      "[150]\ttrain's binary_logloss: 0.321628\tvalid's binary_logloss: 0.321097\n",
      "[200]\ttrain's binary_logloss: 0.321258\tvalid's binary_logloss: 0.321071\n",
      "[250]\ttrain's binary_logloss: 0.321052\tvalid's binary_logloss: 0.321242\n",
      "Early stopping, best iteration is:\n",
      "[175]\ttrain's binary_logloss: 0.32139\tvalid's binary_logloss: 0.321009\n",
      "best logloss on train_set: 0.32138985227098565\n",
      "best logloss on test_set: 0.3210087632845135\n",
      "f1_score on test_set: 0.7951896466975955\n",
      "Fold=9\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.336967\tvalid's binary_logloss: 0.337401\n",
      "[100]\ttrain's binary_logloss: 0.3229\tvalid's binary_logloss: 0.323667\n",
      "[150]\ttrain's binary_logloss: 0.321415\tvalid's binary_logloss: 0.32252\n",
      "[200]\ttrain's binary_logloss: 0.321037\tvalid's binary_logloss: 0.322528\n",
      "[250]\ttrain's binary_logloss: 0.320848\tvalid's binary_logloss: 0.322746\n",
      "Early stopping, best iteration is:\n",
      "[172]\ttrain's binary_logloss: 0.32121\tvalid's binary_logloss: 0.322476\n",
      "best logloss on train_set: 0.32120968644760417\n",
      "best logloss on test_set: 0.3224759091709639\n",
      "f1_score on test_set: 0.7940762399826726\n",
      "train_set上最好的logloss成绩的平均值为：0.38546\n",
      "val_set上最好的logloss成绩的平均值为：0.38682\n",
      "val_set上f1_score成绩的平均值为：0.79387\n"
     ]
    }
   ],
   "source": [
    "for i,(train_index,test_index) in enumerate(skf.split(X,y)):\n",
    "    print(\"Fold=%s\"%(i))\n",
    "    model=clf.fit(X[train_index],y[train_index],\n",
    "                 eval_names=['train','valid'],\n",
    "                 eval_metric='logloss',\n",
    "                  eval_set=[(X[train_index],y[train_index]),(X[test_index],y[test_index])],\n",
    "                 early_stopping_rounds=100,\n",
    "                  verbose=50,)\n",
    "    \n",
    "    trainss=model.best_score_['train']['binary_logloss']\n",
    "    valss=model.best_score_['valid']['binary_logloss']\n",
    "    losstrain+=trainss\n",
    "    lossval+=valss\n",
    "    print(\"best logloss on train_set:\",trainss)\n",
    "    print(\"best logloss on test_set:\",valss)\n",
    "    \n",
    "    val_proba=model.predict_proba(X[test_index],num_iteration=model.best_iteration_)[:,1]\n",
    "    val_pred=np.where(val_proba>0.5,1,0)\n",
    "\n",
    "    fval=f1_score(y[test_index],val_pred)\n",
    "    print(\"f1_score on test_set:\",fval)\n",
    "    fs+=fval\n",
    "    \n",
    "    test_proba=model.predict_proba(testX,num_iteration=model.best_iteration_)[:,1]\n",
    "    sub['ans_%s'%str(i)]=test_proba\n",
    "print(\"train_set上最好的logloss成绩的平均值为：%.5f\"%(losstrain/N))\n",
    "print(\"val_set上最好的logloss成绩的平均值为：%.5f\"%(lossval/N))\n",
    "print(\"val_set上f1_score成绩的平均值为：%.5f\"%(fs/N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['label']=0\n",
    "for i in range(N):\n",
    "    sub['label']+=sub['ans_%s'%str(i)]\n",
    "sub['label']=sub['label']/N\n",
    "sub['label']=sub['label'].apply(lambda x:np.where(x>0.40,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    32911\n",
       "1    17089\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.groupby('label')['label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34178\n"
     ]
    }
   ],
   "source": [
    "print(17089/50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['label'].to_csv('../data/BaselineV1_2.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>2018/11/1<br>过拟合现象之所以严重，与XXY版本对比，可以发现，很大的原因是是因为feature之间相互作用而导致的！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue>2018/11/3<br>1.主要将datadf.groupby(item)['label].agg()修改为traindf.groupby(item,index=False)['label'].agg({sum,count})；<br><br>2.在最后将点击与否的界限设置为0.40；<br><br>3.得到的成绩为0.7128，排名429/2979<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
