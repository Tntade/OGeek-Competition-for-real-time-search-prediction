{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2018/11/1<br>V1.0_0.6231<br>因为在计算ctr的时候是使用了data.groupby().agg()的，所以过拟合现象严重！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red>2018/11/2<br>V1.2_0.7128<br>1.建立在V1.0版本上；<br>2.将data.groupby.agg改成了traindf.grouby.agg，因为data中有一部分的label是-1，所以对成绩产生了非常大的噪声；<br>3.将点击与否的界限从0.5改成了0.4；<br>4.将原先使用lgb.train改成了LGBMClassifier.fit，但是对成绩本身的影响应该不是特别大；<font>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=green>2018/11/3<br>V1.3<br>1.建立在V1.2的基础上；<br>1.对于部分0值变量重新赋予一个新值-1，从而方便使用scaler；<br>2.使用LogisticRegressor进行训练；<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue>2018/11/3<br>V1.4<br>1.对于NaN变量赋予新值-1,重新再跑一遍V1.2模型；<br>2.将V1.3和本次模型进行lgb ensemble；<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2099998, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['query_len']=data['query'].apply(lambda x:len(x.replace('{','').replace('}','').split(',')))\n",
    "# print(data[data['label']!=-1].groupby('query_len')['label'].mean())\n",
    "# print('====================')\n",
    "data['prefix_len']=data['prefix'].apply(lambda x:len(str(x)))\n",
    "# print(data[data['label']!=-1].groupby('prefix_len')['label'].mean())\n",
    "# print('====================')\n",
    "# data['tag_len']=data['tag'].apply(lambda x:len(str(x)))\n",
    "# print(data[data['label']!=-1].groupby('tag_len')['label'].mean())\n",
    "# print('====================')\n",
    "data['title_len']=data['title'].apply(lambda x:len(str(x)))\n",
    "# print(data[data['label']!=-1].groupby('title_len')['label'].mean())\n",
    "# print('====================')\n",
    "# print(data.shape)\n",
    "# print('====================')\n",
    "# print(data.columns)\n",
    "# print('====================')\n",
    "# print(data.describe())\n",
    "# print('====================')\n",
    "# print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "lr_col=['prefix','title','tag','query']\n",
    "for feature in lr_col:\n",
    "    data[feature]=data[feature].astype(str)\n",
    "\n",
    "data['prefix']=le.fit_transform(data['prefix'])\n",
    "data['title']=le.fit_transform(data['title'])\n",
    "data['query']=le.fit_transform(data['query'])\n",
    "data['tag']=le.fit_transform(data['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049998, 8)\n",
      "(50000, 8)\n"
     ]
    }
   ],
   "source": [
    "traindf=data[data['label']!=-1]\n",
    "testdf=data[data['label']==-1]\n",
    "print(traindf.shape)\n",
    "print(testdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=['prefix','query','title','tag','query_len','prefix_len','title_len']\n",
    "for item in col:\n",
    "    temp=traindf.groupby(item,as_index=False)['label'].agg({item+'_click':'sum',item+'_count':'count'})\n",
    "    temp[item+'_ctr']=(temp[item+'_click']/temp[item+'_count'])\n",
    "    traindf = pd.merge(traindf, temp, on=item, how='left')\n",
    "    testdf=pd.merge(testdf,temp,on=item,how='left')\n",
    "    #testdf中有很多是traindf中没有的，所以导致testdf.merger的时候就会出现很多NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(col)):\n",
    "    for j in range(i+1,len(col)):\n",
    "        item_g=[col[i],col[j]]\n",
    "        temp=traindf.groupby(item_g,as_index=False)['label'].agg({'_'.join(item_g)+'_click':'sum','_'.join(item_g)+'_count':'count'})\n",
    "        temp['_'.join(item_g)+'_ctr']=temp['_'.join(item_g)+'_click']/(temp['_'.join(item_g)+'_count']+3)\n",
    "        traindf=pd.merge(traindf,temp,on=item_g,how='left')\n",
    "        testdf=pd.merge(testdf,temp,on=item_g,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([traindf,testdf],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fea in testdf.columns:\n",
    "    testdf[fea]=testdf[fea].fillna('-1')\n",
    "    data[fea]=LabelEncoder().fit_transform(data[fea].apply(str))\n",
    "traindf=data[:traindf.shape[0]]\n",
    "testdf=data[traindf.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049998, 92) (50000, 92)\n"
     ]
    }
   ],
   "source": [
    "print(traindf.shape,testdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===========Train==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testddf=testdf.drop(['label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=traindf.pop('label').values\n",
    "X=traindf.as_matrix()\n",
    "testX=testddf.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train=pd.DataFrame()\n",
    "sub_test=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "losstrain=0\n",
    "lossval=0\n",
    "fs=0\n",
    "ft=0\n",
    "\n",
    "N=10\n",
    "\n",
    "skf=StratifiedKFold(n_splits=N,random_state=1,shuffle=True)\n",
    "\n",
    "clf= LGBMClassifier(boosting_type='gbdt', num_leaves=60, max_depth=-1, \n",
    "                         learning_rate=0.05, n_estimators=2000,objective='binary', \n",
    "                         min_split_gain=0,min_child_weight=5, min_child_samples=10, \n",
    "                         subsample=0.8, subsample_freq=1,colsample_bytree=0.8, \n",
    "                         reg_alpha=3, reg_lambda=5, random_state=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold=0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.336964\tvalid's binary_logloss: 0.337109\n",
      "[100]\ttrain's binary_logloss: 0.322936\tvalid's binary_logloss: 0.323395\n",
      "[150]\ttrain's binary_logloss: 0.321467\tvalid's binary_logloss: 0.322248\n",
      "[200]\ttrain's binary_logloss: 0.321086\tvalid's binary_logloss: 0.322239\n",
      "[250]\ttrain's binary_logloss: 0.320886\tvalid's binary_logloss: 0.322464\n",
      "Early stopping, best iteration is:\n",
      "[170]\ttrain's binary_logloss: 0.321267\tvalid's binary_logloss: 0.322185\n",
      "best logloss on train_set: 0.3212672203670879\n",
      "best logloss on test_set: 0.32218456552549257\n",
      "f1_score on train_set: 0.8009451469807038\n",
      "f1_score on test_set: 0.7995975305268127\n",
      "Fold=1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.337016\tvalid's binary_logloss: 0.336467\n",
      "[100]\ttrain's binary_logloss: 0.323057\tvalid's binary_logloss: 0.322658\n",
      "[150]\ttrain's binary_logloss: 0.321575\tvalid's binary_logloss: 0.321448\n",
      "[200]\ttrain's binary_logloss: 0.321191\tvalid's binary_logloss: 0.321422\n",
      "[250]\ttrain's binary_logloss: 0.320997\tvalid's binary_logloss: 0.321607\n",
      "Early stopping, best iteration is:\n",
      "[175]\ttrain's binary_logloss: 0.321337\tvalid's binary_logloss: 0.321385\n",
      "best logloss on train_set: 0.32133738808224027\n",
      "best logloss on test_set: 0.3213854406940395\n",
      "f1_score on train_set: 0.8007705995960633\n",
      "f1_score on test_set: 0.8015572900173239\n",
      "Fold=2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.337031\tvalid's binary_logloss: 0.336376\n",
      "[100]\ttrain's binary_logloss: 0.32305\tvalid's binary_logloss: 0.322539\n",
      "[150]\ttrain's binary_logloss: 0.321567\tvalid's binary_logloss: 0.321401\n",
      "[200]\ttrain's binary_logloss: 0.321195\tvalid's binary_logloss: 0.321438\n",
      "[250]\ttrain's binary_logloss: 0.320983\tvalid's binary_logloss: 0.321638\n",
      "Early stopping, best iteration is:\n",
      "[173]\ttrain's binary_logloss: 0.321342\tvalid's binary_logloss: 0.321352\n",
      "best logloss on train_set: 0.3213421065627861\n",
      "best logloss on test_set: 0.3213521909649771\n",
      "f1_score on train_set: 0.8009666684383859\n",
      "f1_score on test_set: 0.800178650075368\n",
      "Fold=3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.336864\tvalid's binary_logloss: 0.338086\n",
      "[100]\ttrain's binary_logloss: 0.322864\tvalid's binary_logloss: 0.324509\n",
      "[150]\ttrain's binary_logloss: 0.321377\tvalid's binary_logloss: 0.323357\n",
      "[200]\ttrain's binary_logloss: 0.320995\tvalid's binary_logloss: 0.323358\n",
      "[250]\ttrain's binary_logloss: 0.320787\tvalid's binary_logloss: 0.323573\n",
      "Early stopping, best iteration is:\n",
      "[169]\ttrain's binary_logloss: 0.321187\tvalid's binary_logloss: 0.323299\n",
      "best logloss on train_set: 0.32118736484824356\n",
      "best logloss on test_set: 0.32329874649344403\n",
      "f1_score on train_set: 0.8010183056173167\n",
      "f1_score on test_set: 0.7997911058334939\n",
      "Fold=4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.336754\tvalid's binary_logloss: 0.338931\n",
      "[100]\ttrain's binary_logloss: 0.322746\tvalid's binary_logloss: 0.325268\n",
      "[150]\ttrain's binary_logloss: 0.321261\tvalid's binary_logloss: 0.324065\n",
      "[200]\ttrain's binary_logloss: 0.320894\tvalid's binary_logloss: 0.324068\n",
      "[250]\ttrain's binary_logloss: 0.320691\tvalid's binary_logloss: 0.324274\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttrain's binary_logloss: 0.321098\tvalid's binary_logloss: 0.324005\n",
      "best logloss on train_set: 0.3210982136329796\n",
      "best logloss on test_set: 0.32400450249891105\n",
      "f1_score on train_set: 0.8010336951772625\n",
      "f1_score on test_set: 0.7994908097367114\n",
      "Fold=5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.336811\tvalid's binary_logloss: 0.338311\n",
      "[100]\ttrain's binary_logloss: 0.322788\tvalid's binary_logloss: 0.324783\n",
      "[150]\ttrain's binary_logloss: 0.321318\tvalid's binary_logloss: 0.323702\n",
      "[200]\ttrain's binary_logloss: 0.320924\tvalid's binary_logloss: 0.323714\n",
      "[250]\ttrain's binary_logloss: 0.320709\tvalid's binary_logloss: 0.323921\n",
      "Early stopping, best iteration is:\n",
      "[168]\ttrain's binary_logloss: 0.321127\tvalid's binary_logloss: 0.323655\n",
      "best logloss on train_set: 0.3211267750068811\n",
      "best logloss on test_set: 0.3236546811976009\n",
      "f1_score on train_set: 0.8009940157601998\n",
      "f1_score on test_set: 0.7995202853432258\n",
      "Fold=6\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.337133\tvalid's binary_logloss: 0.336122\n",
      "[100]\ttrain's binary_logloss: 0.323115\tvalid's binary_logloss: 0.322169\n",
      "[150]\ttrain's binary_logloss: 0.321625\tvalid's binary_logloss: 0.321012\n",
      "[200]\ttrain's binary_logloss: 0.321238\tvalid's binary_logloss: 0.32103\n",
      "[250]\ttrain's binary_logloss: 0.321023\tvalid's binary_logloss: 0.321243\n",
      "Early stopping, best iteration is:\n",
      "[171]\ttrain's binary_logloss: 0.321419\tvalid's binary_logloss: 0.32097\n",
      "best logloss on train_set: 0.3214192068966767\n",
      "best logloss on test_set: 0.32096966196211324\n",
      "f1_score on train_set: 0.8006715239218323\n",
      "f1_score on test_set: 0.8025109902391775\n",
      "Fold=7\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.336851\tvalid's binary_logloss: 0.338285\n",
      "[100]\ttrain's binary_logloss: 0.322813\tvalid's binary_logloss: 0.324698\n",
      "[150]\ttrain's binary_logloss: 0.321332\tvalid's binary_logloss: 0.323553\n",
      "[200]\ttrain's binary_logloss: 0.320953\tvalid's binary_logloss: 0.323551\n",
      "[250]\ttrain's binary_logloss: 0.320745\tvalid's binary_logloss: 0.323779\n",
      "Early stopping, best iteration is:\n",
      "[171]\ttrain's binary_logloss: 0.321132\tvalid's binary_logloss: 0.323495\n",
      "best logloss on train_set: 0.3211317382474884\n",
      "best logloss on test_set: 0.32349528710038045\n",
      "f1_score on train_set: 0.8010819145110852\n",
      "f1_score on test_set: 0.7989141238445483\n",
      "Fold=8\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.337111\tvalid's binary_logloss: 0.336238\n",
      "[100]\ttrain's binary_logloss: 0.323104\tvalid's binary_logloss: 0.322308\n",
      "[150]\ttrain's binary_logloss: 0.321644\tvalid's binary_logloss: 0.321124\n",
      "[200]\ttrain's binary_logloss: 0.321269\tvalid's binary_logloss: 0.321129\n",
      "[250]\ttrain's binary_logloss: 0.321066\tvalid's binary_logloss: 0.321324\n",
      "Early stopping, best iteration is:\n",
      "[181]\ttrain's binary_logloss: 0.321356\tvalid's binary_logloss: 0.321054\n",
      "best logloss on train_set: 0.3213560802253669\n",
      "best logloss on test_set: 0.32105356542490066\n",
      "f1_score on train_set: 0.8008972888702625\n",
      "f1_score on test_set: 0.8006311813528155\n",
      "Fold=9\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's binary_logloss: 0.336914\tvalid's binary_logloss: 0.337333\n",
      "[100]\ttrain's binary_logloss: 0.32289\tvalid's binary_logloss: 0.323624\n",
      "[150]\ttrain's binary_logloss: 0.32142\tvalid's binary_logloss: 0.322513\n",
      "[200]\ttrain's binary_logloss: 0.321041\tvalid's binary_logloss: 0.322527\n",
      "[250]\ttrain's binary_logloss: 0.320855\tvalid's binary_logloss: 0.322759\n",
      "Early stopping, best iteration is:\n",
      "[168]\ttrain's binary_logloss: 0.321249\tvalid's binary_logloss: 0.322479\n",
      "best logloss on train_set: 0.32124923088354607\n",
      "best logloss on test_set: 0.3224786115144472\n",
      "f1_score on train_set: 0.8009119138941251\n",
      "f1_score on test_set: 0.8005865284845323\n",
      "mean logloss in train set：0.35338\n",
      "mean logloss in test set：0.35461\n",
      "mean f1 in train set：0.88111\n",
      "mean f1 in test set：0.88038\n"
     ]
    }
   ],
   "source": [
    "for i,(train_index,test_index) in enumerate(skf.split(X,y)):\n",
    "    print(\"Fold=%s\"%(i))\n",
    "    model=clf.fit(X[train_index],y[train_index],\n",
    "                 eval_names=['train','valid'],\n",
    "                 eval_metric='logloss',\n",
    "                  eval_set=[(X[train_index],y[train_index]),(X[test_index],y[test_index])],\n",
    "                 early_stopping_rounds=100,\n",
    "                  verbose=50,)\n",
    "    \n",
    "    trainss=model.best_score_['train']['binary_logloss']\n",
    "    valss=model.best_score_['valid']['binary_logloss']\n",
    "    losstrain+=trainss\n",
    "    lossval+=valss\n",
    "    print(\"best logloss on train_set:\",trainss)\n",
    "    print(\"best logloss on test_set:\",valss)\n",
    "    \n",
    "    train_proba=model.predict_proba(X[train_index],num_iteration=model.best_iteration_)[:,1]\n",
    "    train_pred=np.where(train_proba>0.37,1,0)\n",
    "    ftrain=f1_score(y[train_index],train_pred)\n",
    "    print(\"f1_score on train_set:\",ftrain)\n",
    "    ft+=ftrain\n",
    "    \n",
    "    val_proba=model.predict_proba(X[test_index],num_iteration=model.best_iteration_)[:,1]\n",
    "    val_pred=np.where(val_proba>0.37,1,0)\n",
    "    fval=f1_score(y[test_index],val_pred)\n",
    "    print(\"f1_score on test_set:\",fval)\n",
    "    fs+=fval\n",
    "    \n",
    "    train_all=model.predict_proba(X,num_iteration=model.best_iteration_)[:,1]\n",
    "    sub_train['ans_%s'%str(i)]=train_all\n",
    "    test_proba=model.predict_proba(testX,num_iteration=model.best_iteration_)[:,1]\n",
    "    sub_test['ans_%s'%str(i)]=test_proba\n",
    "print(\"mean logloss in train set：%.5f\"%(losstrain/N))\n",
    "print(\"mean logloss in test set：%.5f\"%(lossval/N))\n",
    "print(\"mean f1 in train set：%.5f\"%(ft/N))\n",
    "print(\"mean f1 in test set：%.5f\"%(fs/N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train['label']=0\n",
    "for i in range(N):\n",
    "    sub_train['label']+=sub_train['ans_%s'%str(i)]\n",
    "sub_train['label']=sub_train['label']/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test['label']=0\n",
    "for i in range(N):\n",
    "    sub_test['label']+=sub_test['ans_%s'%str(i)]\n",
    "sub_test['label']=sub_test['label']/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049998, 11)\n"
     ]
    }
   ],
   "source": [
    "print(sub_train.shape)\n",
    "\n",
    "print(sub_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train['label'].to_csv('../data/ensemble/lgb_train.csv',index=True)\n",
    "sub_test['label'].to_csv('../data/ensemble/lgb_test.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============ensemble==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "gc.collect()\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train=pd.read_csv('../data/ensemble/lgb_train.csv', names= ['lgb_label'], header= None)\n",
    "lgb_test=pd.read_csv('../data/ensemble/lgb_test.csv',names= ['lgb_label'], header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train=pd.read_csv('../data/ensemble/lr_train.csv',names= ['lr_label'], header= None)\n",
    "lr_test=pd.read_csv('../data/ensemble/lr_test.csv',names= ['lr_label'], header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049998, 3)\n"
     ]
    }
   ],
   "source": [
    "ntrain=pd.concat([lgb_train,lr_train],axis=1)\n",
    "ntrain['label']=data['label'][data['label']!=-1]\n",
    "print(ntrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    }
   ],
   "source": [
    "ntest=pd.concat([lgb_test,lr_test],axis=1)\n",
    "print(ntest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt=0\n",
    "lv=0\n",
    "fin=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=ntrain.pop('label').values\n",
    "x=ntrain.as_matrix()\n",
    "testx=ntest.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb=LGBMClassifier(boosting_type='gbdt', num_leaves=48, max_depth=-1, \n",
    "                         learning_rate=0.05, n_estimators=4000,objective='binary', \n",
    "                         min_split_gain=0,min_child_weight=5, min_child_samples=10, \n",
    "                         subsample=0.8, subsample_freq=1,colsample_bytree=0.8, \n",
    "                         reg_alpha=3, reg_lambda=5, random_state=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=5\n",
    "sk=StratifiedKFold(n_splits=M,random_state=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold=0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttrain's binary_logloss: 0.323148\tval's binary_logloss: 0.322682\n",
      "[400]\ttrain's binary_logloss: 0.322298\tval's binary_logloss: 0.321843\n",
      "[600]\ttrain's binary_logloss: 0.322034\tval's binary_logloss: 0.321567\n",
      "[800]\ttrain's binary_logloss: 0.321865\tval's binary_logloss: 0.321395\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-cc39d05ecf8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     mod=lgb.fit(x[train_index],Y[train_index],eval_names=['train','val'],eval_metric='logloss',\n\u001b[0;32m      4\u001b[0m         \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         early_stopping_rounds=100,verbose=200,)\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mltrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'binary_logloss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    693\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m                                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m    696\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    472\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    202\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1526\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1527\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1528\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1529\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1530\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i,(train_index,test_index) in enumerate(sk.split(x,Y)):\n",
    "    print(\"Fold=%s\"%str(i))\n",
    "    mod=lgb.fit(x[train_index],Y[train_index],eval_names=['train','val'],eval_metric='logloss',\n",
    "        eval_set=[(x[train_index],Y[train_index]),(x[test_index],Y[test_index])],\n",
    "        early_stopping_rounds=100,verbose=200,)\n",
    "    \n",
    "    ltrain=mod.best_score_['train']['binary_logloss']\n",
    "    lval=mod.best_score_['val']['binary_logloss']\n",
    "    lt+=ltrain\n",
    "    lv+=lval\n",
    "    print('best logloss on train set:%.5f'%ltrain)\n",
    "    print('best logloss on test set:%.5f'%lval)\n",
    "    \n",
    "    ytrain=mod.predict(x[train_index])\n",
    "    print('f1 score on train set:%.5f'%(f1_score(Y[train_index],ytrain)))\n",
    "    \n",
    "    yval=mod.predict(x[test_index])\n",
    "    print('f1 score on train set:%.5f'%(f1_score(Y[test_index],yval)))\n",
    "    \n",
    "    ytest=mod.predict_proba(testx)\n",
    "    fin['ans_%s'%str(i)]=ytest\n",
    "print('mean logloss on train set:%.5f'%(lt/M))\n",
    "print('mean logloss on test set:%.5f'%(lv/M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin['label']=0\n",
    "for i in range(M):\n",
    "    fin['label']+=fin['ans_%s'%str(i)]\n",
    "fin['label']=fin['label']/M\n",
    "fin['label']=fin['label'].apply(lambda x:np.where(x>0.37,1,0))\n",
    "print(fin['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
