{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('./data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2099998, 5)\n",
      "(50000, 5)\n",
      " 0    1287218\n",
      " 1     762780\n",
      "-1      50000\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data[data['label']==-1].shape)\n",
    "print(data.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['query_len']=data['query'].apply(lambda x:len(x.replace('{','').replace('}','').split(',')))\n",
    "# print(data[data['label']!=-1].groupby('query_len')['label'].mean())\n",
    "# print('====================')\n",
    "data['prefix_len']=data['prefix'].apply(lambda x:len(str(x)))\n",
    "# print(data[data['label']!=-1].groupby('prefix_len')['label'].mean())\n",
    "# print('====================')\n",
    "data['tag_len']=data['tag'].apply(lambda x:len(str(x)))\n",
    "# print(data[data['label']!=-1].groupby('tag_len')['label'].mean())\n",
    "# print('====================')\n",
    "data['title_len']=data['title'].apply(lambda x:len(str(x)))\n",
    "# print(data[data['label']!=-1].groupby('title_len')['label'].mean())\n",
    "# print('====================')\n",
    "# print(data.shape)\n",
    "# print('====================')\n",
    "# print(data.columns)\n",
    "# print('====================')\n",
    "# print(data.describe())\n",
    "# print('====================')\n",
    "# print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "lr_col=['prefix','title','tag','query']\n",
    "for feature in lr_col:\n",
    "    data[feature]=data[feature].astype(str)\n",
    "\n",
    "data['prefix']=le.fit_transform(data['prefix'])\n",
    "data['title']=le.fit_transform(data['title'])\n",
    "data['query']=le.fit_transform(data['query'])\n",
    "data['tag']=le.fit_transform(data['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2099998, 33)\n"
     ]
    }
   ],
   "source": [
    "#对应不同特征的点击率的构造\n",
    "train_data=data[['prefix','query','title','tag','query_len','prefix_len','tag_len','title_len','label']]\n",
    "col=['prefix','query','title','tag','query_len','prefix_len','tag_len','title_len']\n",
    "for item in col:\n",
    "    temp=train_data.groupby(item,as_index=False)['label'].agg({item+'_click':'sum',item+'_count':'count'})\n",
    "    temp[item+'_ctr']=(temp[item+'_click']/temp[item+'_count'])\n",
    "    train_data = pd.merge(train_data, temp, on=item, how='left')\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2099998, 51)\n"
     ]
    }
   ],
   "source": [
    "cols=['prefix','query','title','tag']\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i+1,len(cols)):\n",
    "        item_g=[cols[i],cols[j]]\n",
    "        temp=data[['prefix','query','title','tag','label']].groupby(item_g,as_index=False)['label'].agg({'_'.join(item_g)+'_click':'sum','_'.join(item_g)+'count':'count'})\n",
    "        temp['_'.join(item_g)+'_ctr']=temp['_'.join(item_g)+'_click']/(temp['_'.join(item_g)+'count']+3)\n",
    "        train_data=pd.merge(train_data,temp,on=item_g,how='left')\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dd=train_data.drop(['prefix','query','title','tag','query_len','prefix_len','tag_len','title_len','label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2099998, 51)\n"
     ]
    }
   ],
   "source": [
    "data=pd.concat([data,train_dd],axis=1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['prefix', 'query', 'title', 'tag', 'label', 'query_len', 'prefix_len',\n",
      "       'tag_len', 'title_len', 'prefix_click', 'prefix_count', 'prefix_ctr',\n",
      "       'query_click', 'query_count', 'query_ctr', 'title_click', 'title_count',\n",
      "       'title_ctr', 'tag_click', 'tag_count', 'tag_ctr', 'query_len_click',\n",
      "       'query_len_count', 'query_len_ctr', 'prefix_len_click',\n",
      "       'prefix_len_count', 'prefix_len_ctr', 'tag_len_click', 'tag_len_count',\n",
      "       'tag_len_ctr', 'title_len_click', 'title_len_count', 'title_len_ctr',\n",
      "       'prefix_query_click', 'prefix_querycount', 'prefix_query_ctr',\n",
      "       'prefix_title_click', 'prefix_titlecount', 'prefix_title_ctr',\n",
      "       'prefix_tag_click', 'prefix_tagcount', 'prefix_tag_ctr',\n",
      "       'query_title_click', 'query_titlecount', 'query_title_ctr',\n",
      "       'query_tag_click', 'query_tagcount', 'query_tag_ctr', 'title_tag_click',\n",
      "       'title_tagcount', 'title_tag_ctr'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去掉方差为0的没有意义的数据\n",
    "# v=data[data['label']!=-1].var()\n",
    "# zero_fea=v[v==0].index.values.tolist()\n",
    "\n",
    "# print(zero_fea)\n",
    "# 只有['query_len_15']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===========Train==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049998, 51) (50000, 51)\n"
     ]
    }
   ],
   "source": [
    "traindf=data[data['label']!=-1]\n",
    "testdf=data[data['label']==-1]\n",
    "print(traindf.shape,testdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.to_csv('./data/final_train1.csv',index=False)\n",
    "testddf=testdf.drop(['label'],axis=1)\n",
    "testddf.to_csv('./data/final_test1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=traindf.pop('label').values\n",
    "X=traindf.as_matrix()\n",
    "testX=testddf.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "logloss=[]\n",
    "losstrain=0\n",
    "lossval=0\n",
    "fs=0\n",
    "ft=0\n",
    "\n",
    "N=5\n",
    "\n",
    "params={'boosting_type':'gbdt','objective':'binary','metric':'binary_logloss',\n",
    "                    'num_leaves':50,'learning_rate':0.05,'feature_fraction':0.9,\n",
    "                       'bagging_fraction':0.8,'bagging_freq':5,'verbose':1}\n",
    "\n",
    "skf=StratifiedKFold(n_splits=N,random_state=1,shuffle=True)\n",
    "\n",
    "# clf=lgb.LGBMClassifier(boosting_type='gbdt',objective='binary',metric='binary_logloss',\n",
    "#                     num_leaves=500,learning_rate=0.05,feature_fraction=0.9,\n",
    "#                        bagging_fraction=0.8,bagging_freq=5,max_depth=-1,\n",
    "#                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold=0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's binary_logloss: 0.345906\tvalid_1's binary_logloss: 0.345435\n",
      "[100]\ttraining's binary_logloss: 0.332722\tvalid_1's binary_logloss: 0.332467\n",
      "[150]\ttraining's binary_logloss: 0.331001\tvalid_1's binary_logloss: 0.331071\n",
      "[200]\ttraining's binary_logloss: 0.33022\tvalid_1's binary_logloss: 0.330646\n",
      "[250]\ttraining's binary_logloss: 0.329684\tvalid_1's binary_logloss: 0.330553\n",
      "[300]\ttraining's binary_logloss: 0.329229\tvalid_1's binary_logloss: 0.33057\n",
      "Early stopping, best iteration is:\n",
      "[261]\ttraining's binary_logloss: 0.329574\tvalid_1's binary_logloss: 0.330543\n",
      "0.7914858581862936\n",
      "0.7916223557382934\n",
      "Fold=1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's binary_logloss: 0.34565\tvalid_1's binary_logloss: 0.346337\n",
      "[100]\ttraining's binary_logloss: 0.332491\tvalid_1's binary_logloss: 0.333526\n",
      "[150]\ttraining's binary_logloss: 0.330706\tvalid_1's binary_logloss: 0.332072\n",
      "[200]\ttraining's binary_logloss: 0.329975\tvalid_1's binary_logloss: 0.331744\n",
      "[250]\ttraining's binary_logloss: 0.329409\tvalid_1's binary_logloss: 0.331615\n",
      "[300]\ttraining's binary_logloss: 0.328974\tvalid_1's binary_logloss: 0.331609\n",
      "Early stopping, best iteration is:\n",
      "[282]\ttraining's binary_logloss: 0.329126\tvalid_1's binary_logloss: 0.331605\n",
      "0.7929117982030625\n",
      "0.7901918933408862\n",
      "Fold=2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's binary_logloss: 0.3454\tvalid_1's binary_logloss: 0.34731\n",
      "[100]\ttraining's binary_logloss: 0.33221\tvalid_1's binary_logloss: 0.33461\n",
      "[150]\ttraining's binary_logloss: 0.330426\tvalid_1's binary_logloss: 0.333202\n",
      "[200]\ttraining's binary_logloss: 0.329687\tvalid_1's binary_logloss: 0.332915\n",
      "[250]\ttraining's binary_logloss: 0.329168\tvalid_1's binary_logloss: 0.332809\n",
      "[300]\ttraining's binary_logloss: 0.328692\tvalid_1's binary_logloss: 0.332738\n",
      "Early stopping, best iteration is:\n",
      "[297]\ttraining's binary_logloss: 0.328708\tvalid_1's binary_logloss: 0.332733\n",
      "0.792099582759003\n",
      "0.7899338950448376\n",
      "Fold=3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's binary_logloss: 0.345769\tvalid_1's binary_logloss: 0.346033\n",
      "[100]\ttraining's binary_logloss: 0.332623\tvalid_1's binary_logloss: 0.333135\n",
      "[150]\ttraining's binary_logloss: 0.330822\tvalid_1's binary_logloss: 0.331663\n",
      "[200]\ttraining's binary_logloss: 0.3301\tvalid_1's binary_logloss: 0.331354\n",
      "[250]\ttraining's binary_logloss: 0.329558\tvalid_1's binary_logloss: 0.331222\n",
      "[300]\ttraining's binary_logloss: 0.329122\tvalid_1's binary_logloss: 0.331214\n",
      "Early stopping, best iteration is:\n",
      "[285]\ttraining's binary_logloss: 0.329232\tvalid_1's binary_logloss: 0.331181\n",
      "0.7920043594738169\n",
      "0.790627919888418\n",
      "Fold=4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's binary_logloss: 0.345963\tvalid_1's binary_logloss: 0.345413\n",
      "[100]\ttraining's binary_logloss: 0.332772\tvalid_1's binary_logloss: 0.332301\n",
      "[150]\ttraining's binary_logloss: 0.331032\tvalid_1's binary_logloss: 0.33091\n",
      "[200]\ttraining's binary_logloss: 0.330267\tvalid_1's binary_logloss: 0.330562\n",
      "[250]\ttraining's binary_logloss: 0.329729\tvalid_1's binary_logloss: 0.330469\n",
      "[300]\ttraining's binary_logloss: 0.329251\tvalid_1's binary_logloss: 0.33044\n",
      "Early stopping, best iteration is:\n",
      "[295]\ttraining's binary_logloss: 0.32929\tvalid_1's binary_logloss: 0.330429\n",
      "0.7920865893808826\n",
      "0.7918043040927764\n",
      "train_set上最好的logloss成绩的平均值为：0.32919\n",
      "val_set上最好的logloss成绩的平均值为：0.33130\n",
      "train_set上f1_score成绩的平均值为：0.79212\n",
      "val_set上f1_score成绩的平均值为：0.79084\n"
     ]
    }
   ],
   "source": [
    "for i,(train_index,test_index) in enumerate(skf.split(X,y)):\n",
    "    print(\"Fold=%s\"%i)\n",
    "    X_train,X_test,y_train,y_test=X[train_index],X[test_index],y[train_index],y[test_index]\n",
    "    \n",
    "    lgb_train=lgb.Dataset(X_train,y_train)\n",
    "    lgb_val=lgb.Dataset(X_test,y_test,reference=lgb_train)\n",
    "    \n",
    "    model=lgb.train(params,lgb_train,num_boost_round=5000,valid_sets=[lgb_train,lgb_val],\n",
    "                    early_stopping_rounds=50,verbose_eval=50,)\n",
    "    \n",
    "    trainss=model.best_score['training']['binary_logloss']\n",
    "    valss=model.best_score['valid_1']['binary_logloss']\n",
    "    losstrain+=trainss\n",
    "    lossval+=valss\n",
    "    \n",
    "    pred_proba=model.predict(X_test,num_iteration=model.best_iteration)\n",
    "#     print(pred_proba)\n",
    "    pred_val=np.where(pred_proba>0.5,1,0)\n",
    "#     print(pred_val)\n",
    "\n",
    "    ftrain=f1_score(y_train,np.where(model.predict(X_train,num_iteration=model.best_iteration)>0.5,1,0))\n",
    "    print(ftrain)\n",
    "    ft+=ftrain\n",
    "    \n",
    "    fval=f1_score(y_test,pred_val)\n",
    "    print(fval)\n",
    "    fs+=fval\n",
    "    \n",
    "    pred_test=model.predict(testX,num_iteration=model.best_iteration)\n",
    "    sub['ans_%s'%str(i)]=pred_test\n",
    "print(\"train_set上最好的logloss成绩的平均值为：%.5f\"%(losstrain/N))\n",
    "print(\"val_set上最好的logloss成绩的平均值为：%.5f\"%(lossval/N))\n",
    "print(\"train_set上f1_score成绩的平均值为：%.5f\"%(ft/N))\n",
    "print(\"val_set上f1_score成绩的平均值为：%.5f\"%(fs/N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ans_0     ans_1     ans_2     ans_3     ans_4\n",
      "0      0.014057  0.018538  0.013557  0.019247  0.013875\n",
      "1      0.530977  0.539832  0.538347  0.539643  0.533055\n",
      "2      0.589679  0.612567  0.585650  0.566930  0.603303\n",
      "3      0.014473  0.013645  0.015079  0.012150  0.010269\n",
      "4      0.075484  0.080884  0.075259  0.073760  0.078914\n",
      "5      0.006348  0.006490  0.008296  0.009014  0.007018\n",
      "6      0.823319  0.816836  0.830985  0.826371  0.816116\n",
      "7      0.011301  0.010516  0.010688  0.010285  0.010365\n",
      "8      0.480792  0.476122  0.495312  0.466013  0.478915\n",
      "9      0.037361  0.038376  0.040930  0.036188  0.036807\n",
      "10     0.006291  0.004714  0.004606  0.006447  0.006690\n",
      "11     0.505602  0.485726  0.506491  0.491682  0.498171\n",
      "12     0.004049  0.011405  0.004420  0.003196  0.003407\n",
      "13     0.007704  0.003913  0.006445  0.003360  0.005751\n",
      "14     0.284699  0.277025  0.286368  0.280425  0.284581\n",
      "15     0.084564  0.086085  0.084410  0.087969  0.089930\n",
      "16     0.630350  0.607306  0.619467  0.623222  0.617701\n",
      "17     0.163794  0.161384  0.167839  0.164686  0.165844\n",
      "18     0.533034  0.536186  0.547060  0.508666  0.521387\n",
      "19     0.366477  0.371601  0.367568  0.380281  0.375056\n",
      "20     0.010761  0.007982  0.017309  0.011473  0.010659\n",
      "21     0.014210  0.021633  0.032793  0.020523  0.014717\n",
      "22     0.753638  0.758399  0.753904  0.751534  0.758063\n",
      "23     0.128713  0.132064  0.130426  0.128744  0.133430\n",
      "24     0.250636  0.246100  0.280504  0.294807  0.231325\n",
      "25     0.087924  0.094539  0.091264  0.099684  0.096757\n",
      "26     0.000084  0.000060  0.000034  0.000064  0.000040\n",
      "27     0.972737  0.975838  0.971658  0.971048  0.970854\n",
      "28     0.000026  0.000035  0.000018  0.000029  0.000016\n",
      "29     0.039265  0.036293  0.035806  0.038105  0.038317\n",
      "...         ...       ...       ...       ...       ...\n",
      "49970  0.000023  0.000011  0.000007  0.000012  0.000007\n",
      "49971  0.028790  0.025333  0.014401  0.014745  0.014536\n",
      "49972  0.000133  0.000099  0.000057  0.000092  0.000063\n",
      "49973  0.000396  0.000260  0.000129  0.000211  0.000144\n",
      "49974  0.000022  0.000010  0.000005  0.000009  0.000006\n",
      "49975  0.810841  0.846076  0.868870  0.837719  0.831206\n",
      "49976  0.614315  0.623281  0.568590  0.640252  0.618231\n",
      "49977  0.000024  0.000011  0.000008  0.000009  0.000007\n",
      "49978  0.000023  0.000007  0.000004  0.000008  0.000006\n",
      "49979  0.613514  0.688149  0.595113  0.700706  0.676500\n",
      "49980  0.000026  0.000011  0.000007  0.000017  0.000006\n",
      "49981  0.041256  0.031376  0.033270  0.040326  0.041237\n",
      "49982  0.121575  0.088390  0.141561  0.082739  0.108497\n",
      "49983  0.000017  0.000009  0.000009  0.000011  0.000007\n",
      "49984  0.136041  0.109771  0.121347  0.162228  0.142088\n",
      "49985  0.000135  0.000126  0.000053  0.000056  0.000085\n",
      "49986  0.413421  0.440571  0.410821  0.438822  0.418577\n",
      "49987  0.397156  0.365745  0.305898  0.303815  0.309586\n",
      "49988  0.000041  0.000016  0.000008  0.000045  0.000009\n",
      "49989  0.000037  0.000011  0.000006  0.000014  0.000006\n",
      "49990  0.003839  0.003477  0.003075  0.002975  0.003782\n",
      "49991  0.000144  0.000124  0.000062  0.000063  0.000060\n",
      "49992  0.000182  0.000159  0.000142  0.000084  0.000081\n",
      "49993  0.613514  0.688149  0.595113  0.700706  0.676500\n",
      "49994  0.895085  0.887996  0.877448  0.903366  0.880172\n",
      "49995  0.058897  0.055468  0.078949  0.078052  0.103361\n",
      "49996  0.000019  0.000014  0.000006  0.000018  0.000006\n",
      "49997  0.000018  0.000009  0.000006  0.000011  0.000007\n",
      "49998  0.025616  0.018412  0.027478  0.024926  0.026197\n",
      "49999  0.006161  0.007816  0.009124  0.007163  0.012732\n",
      "\n",
      "[50000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['label']=0\n",
    "for i in range(N):\n",
    "    sub['label']+=sub['ans_%s'%str(i)]\n",
    "sub['label']=sub['label']/N\n",
    "sub['label']=sub['label'].apply(lambda x:np.where(x>0.5,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ans_0</th>\n",
       "      <th>ans_1</th>\n",
       "      <th>ans_2</th>\n",
       "      <th>ans_3</th>\n",
       "      <th>ans_4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014057</td>\n",
       "      <td>0.018538</td>\n",
       "      <td>0.013557</td>\n",
       "      <td>0.019247</td>\n",
       "      <td>0.013875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.530977</td>\n",
       "      <td>0.539832</td>\n",
       "      <td>0.538347</td>\n",
       "      <td>0.539643</td>\n",
       "      <td>0.533055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.589679</td>\n",
       "      <td>0.612567</td>\n",
       "      <td>0.585650</td>\n",
       "      <td>0.566930</td>\n",
       "      <td>0.603303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014473</td>\n",
       "      <td>0.013645</td>\n",
       "      <td>0.015079</td>\n",
       "      <td>0.012150</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.075484</td>\n",
       "      <td>0.080884</td>\n",
       "      <td>0.075259</td>\n",
       "      <td>0.073760</td>\n",
       "      <td>0.078914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ans_0     ans_1     ans_2     ans_3     ans_4  label\n",
       "0  0.014057  0.018538  0.013557  0.019247  0.013875      0\n",
       "1  0.530977  0.539832  0.538347  0.539643  0.533055      1\n",
       "2  0.589679  0.612567  0.585650  0.566930  0.603303      1\n",
       "3  0.014473  0.013645  0.015079  0.012150  0.010269      0\n",
       "4  0.075484  0.080884  0.075259  0.073760  0.078914      0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['label'].to_csv('./data/BaselineV1_mean.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    38265\n",
      "1    11735\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(sub.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    38262\n",
      "1    11738\n",
      "Name: sum, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sub['sum']=0\n",
    "for i in range(N):\n",
    "    sub['ans_%s'%str(i)]=sub['ans_%s'%str(i)].apply(lambda x:np.where(x>0.5,1,0))\n",
    "    sub['sum']+=sub['ans_%s'%str(i)]\n",
    "sub['sum']=sub['sum'].apply(lambda x:np.where(x>2.5,1,0))\n",
    "print(sub['sum'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['sum'].to_csv('./data/BaselineV1_vote.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 成绩为0.6231，非常的差！过拟合现象非常严重！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>2018/11/1<br>过拟合现象之所以严重，与XXY版本对比，可以发现，很大的原因是是因为feature之间相互作用而导致的！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
