{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2018/11/1<br>V1.0_0.6231<br>因为在计算ctr的时候是使用了data.groupby().agg()的，所以过拟合现象严重！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red>2018/11/2<br>V1.2_0.7128<br>1.建立在V1.0版本上；<br>2.将data.groupby.agg改成了traindf.grouby.agg，因为data中有一部分的label是-1，所以对成绩产生了非常大的噪声；<br>3.将点击与否的界限从0.5改成了0.4；<br>4.将原先使用lgb.train改成了LGBMClassifier.fit，但是对成绩本身的影响应该不是特别大；<font>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=green>2018/11/3<br>V1.3<br>1.建立在V1.2的基础上；<br>1.对于部分0值变量重新赋予一个新值-1，从而方便使用scaler；<br>2.使用LogisticRegressor进行训练；<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue>2018/11/3<br>V1.4<br>1.对于NaN变量赋予新值-1,重新再跑一遍V1.2模型；<br>2.将V1.3和本次模型进行lgb ensemble；<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=black>2018/11/3<br>V1.5<br>1.ensemble with lr；<br>2.fillna('-1')然后再LabelEncoder()；<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red>2018/11/3<br>V1.6<br>1.combine V1.3 and V1.4；<br>2.将所有函数进行封装，从而达到自动化效果；<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=green>2018/11/4<br>V1.7<br>1.在V1.6的基础上,在lr_fit和lgb_fit中增加了stack的内容；<br><br>2.模型中加入了stack一层，但是很明显V1.6已经让电脑跑不动了，所以准备V1.8直接作stack，且觉得如果使用def封装，代码跑起来很慢，所以决定取消def封装，且代码中做出明显的标注，从而展示每一段代码的作用，方便2018/11/6的18:00解压25万B榜数据，直接修改代码后就可以跑;<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==========base data solve=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_data(data):\n",
    "    data['query_len']=data['query'].apply(lambda x:len(x.replace('{','').replace('}','').split(',')))\n",
    "    data['prefix_len']=data['prefix'].apply(lambda x:len(str(x)))\n",
    "    data['title_len']=data['title'].apply(lambda x:len(str(x))) \n",
    "    \n",
    "    le=LabelEncoder()\n",
    "    le_cols=['prefix','title','query','tag']\n",
    "    for feature in le_cols:\n",
    "        data[feature]=data[feature].astype(str)\n",
    "    data['prefix']=le.fit_transform(data['prefix'])\n",
    "    data['title']=le.fit_transform(data['title'])\n",
    "    data['query']=le.fit_transform(data['query'])\n",
    "    data['tag']=le.fit_transform(data['tag'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ctr(data):\n",
    "    traindf=data[data['label']!=-1]\n",
    "    testdf=data[data['label']==-1]\n",
    "    print(traindf.shape)\n",
    "    print(testdf.shape)\n",
    "    \n",
    "    col=['prefix','query','title','tag','prefix_len','query_len','title_len']\n",
    "    for item in col:\n",
    "        temp=traindf.groupby(item,as_index=False)['label'].agg({item+'_click':'sum',item+'_count':'count'})\n",
    "        temp[item+'_ctr']=(temp[item+'_click']/temp[item+'_count'])\n",
    "        traindf = pd.merge(traindf, temp, on=item, how='left')\n",
    "        testdf=pd.merge(testdf,temp,on=item,how='left')\n",
    "    \n",
    "    for i in range(len(col)):\n",
    "        for j in range(i+1,len(col)):\n",
    "            item_g=[col[i],col[j]]\n",
    "            temp=traindf.groupby(item_g,as_index=False)['label'].agg({'_'.join(item_g)+'_click':'sum','_'.join(item_g)+'_count':'count'})\n",
    "            temp['_'.join(item_g)+'_ctr']=temp['_'.join(item_g)+'_click']/(temp['_'.join(item_g)+'_count']+3)\n",
    "            traindf=pd.merge(traindf,temp,on=item_g,how='left')\n",
    "            testdf=pd.merge(testdf,temp,on=item_g,how='left')\n",
    "    \n",
    "    return traindf,testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getxy(traindf,testdf):\n",
    "#     testddf=testdf.drop(['label'],axis=1)\n",
    "#     print(traindf.shape,testddf.shape)\n",
    "\n",
    "#     y=traindf.pop('label').values\n",
    "#     X=traindf.as_matrix()\n",
    "#     testX=testddf.as_matrix()\n",
    "    \n",
    "#     return X,y,testX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_fit(clf,X,y,testX,N):\n",
    "\n",
    "    sub_train=pd.DataFrame()\n",
    "    sub_test=pd.DataFrame()\n",
    "    stacklr=np.zeros((2049998,1))\n",
    "    stackx=np.zeros((50000,N))\n",
    "    stackX=np.zeros((50000,1))\n",
    "    \n",
    "    skf=StratifiedKFold(n_splits=N,random_state=1,shuffle=True)\n",
    "    for i,(train_index,test_index) in enumerate(skf.split(X,y)):\n",
    "        print(\"Fold=%s\"%i)\n",
    "        clf.fit(X[train_index],y[train_index])\n",
    "        \n",
    "        #主要看train和val上的成绩，确认拟合程度\n",
    "        train_pred=clf.predict_proba(X[train_index])[:,1]\n",
    "        trainf=f1_score(y[train_index],(np.where(train_pred>0.37,1,0)))\n",
    "        print(\"f1 in train set:\",trainf)\n",
    "    \n",
    "        val_pred=clf.predict_proba(X[test_index])[:,1]\n",
    "        valf=f1_score(y[test_index],(np.where(val_pred>0.37,1,0)))\n",
    "        print(\"f1 in test set:\",valf)\n",
    "        #将每一次的Val进行保存，以备后续stacking直接使用，由于是ndarrya类型，故可以直接fit(ndarrayX,ndarrayY)\n",
    "        stacklr[test_index,0]=val_pred\n",
    "        \n",
    "        #将all_train进行保存，可以作为第二层的特征进行训练\n",
    "        train_all=clf.predict_proba(X)[:,1]\n",
    "        sub_train['ans_%s'%i]=train_all\n",
    "        \n",
    "        #all_test进行保存，还可用于blending\n",
    "        test_proba=clf.predict_proba(testX)[:,1]\n",
    "        sub_test['ans_%s'%str(i)]=test_proba\n",
    "        stackx[:,i]=test_proba\n",
    "    stackX[:,0]=stackx.mean()\n",
    "    return sub_train,sub_test,stacklr,stackX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_fit(clf,X,y,testX,N,off_test=None):    \n",
    "    sub_train=pd.DataFrame()\n",
    "    sub_test=pd.DataFrame()\n",
    "    stacklgb=np.zeros((2049998,1))\n",
    "    \n",
    "    if off_test==True:\n",
    "        X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "        model=clf.fit(X_train,y_train,eval_metric='logloss',eval_names=['train','valid']\n",
    "                  eval_set=[(X_train,y_train),(X_test,y_test)],early_stopping_rounds=100,\n",
    "                  verbose=50,)\n",
    "        return model.best_score_['valid']['binary_logloss'],model.feature_importances_\n",
    "    \n",
    "    else off_test==False:    \n",
    "        skf=StratifiedKFold(n_splits=N,random_state=1,shuffle=True)\n",
    "        for i,(train_index,test_index) in enumerate(skf.split(X,y)):\n",
    "            print(\"Fold=%s\"%(i))\n",
    "            model=clf.fit(X[train_index],y[train_index],\n",
    "                   eval_names=['train','valid'],\n",
    "                    eval_metric='logloss',\n",
    "                    eval_set=[(X[train_index],y[train_index]),(X[test_index],y[test_index])],\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose=100,)\n",
    "            print(\"best logloss on train_set:\",(model.best_score_['train']['binary_logloss']))\n",
    "            print(\"best logloss on test_set:\",(model.best_score_['valid']['binary_logloss']))\n",
    "    \n",
    "            train_proba=model.predict_proba(X[train_index],num_iteration=model.best_iteration_)[:,1]\n",
    "            ftrain=f1_score(y[train_index],(np.where(train_proba>0.37,1,0)))\n",
    "            print(\"f1_score on train_set:%.5f\"%ftrain)\n",
    "    \n",
    "            val_proba=model.predict_proba(X[test_index],num_iteration=model.best_iteration_)[:,1]\n",
    "            fval=f1_score(y[test_index],(np.where(val_proba>0.37,1,0)))\n",
    "            print(\"f1_score on val_set:%.5f\"%fval)\n",
    "            #将每一次的Val进行保存，以备后续stacking直接使用，由于是ndarrya类型，故可以直接fit(ndarrayX,ndarrayY)\n",
    "            stacklgb[test_index,0]=val_proba\n",
    "    \n",
    "            train_all=model.predict_proba(X,num_iteration=model.best_iteration_)[:,1]\n",
    "            sub_train['ans_%s'%str(i)]=train_all\n",
    "        \n",
    "            test_proba=model.predict_proba(testX,num_iteration=model.best_iteration_)[:,1]\n",
    "            sub_test['ans_%s'%str(i)]=test_proba\n",
    "    \n",
    "       return sub_train,sub_test,stacklgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_feature(df,N):\n",
    "    df['label']=0\n",
    "    for i in range(N):\n",
    "        df['label']+=df['ans_%s'%str(i)]\n",
    "    df['label']=df['label']/N\n",
    "    print(df.shape)\n",
    "    \n",
    "    ndf=pd.DataFrame()\n",
    "    ndf['label']=df['label']\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>==================第一层训练===============<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========加载数据==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_table('../data/train.txt', \n",
    "        names= ['prefix','query','title','tag','label'], header= None, encoding='utf-8').astype(str) \n",
    "#train_data中删除了一行\n",
    "\n",
    "val_data = pd.read_table('../data/vali.txt', \n",
    "        names = ['prefix','query','title','tag','label'], header = None, encoding='utf-8').astype(str)\n",
    "\n",
    "test_data = pd.read_table('../data/test.txt',\n",
    "        names = ['prefix','query','title','tag'],header = None, encoding='utf-8').astype(str)\n",
    "\n",
    "train_data = train_data[train_data['label'] != '音乐' ]\n",
    "test_data['label'] = -1\n",
    "\n",
    "train_data= pd.concat([train_data,val_data])\n",
    "\n",
    "train_data['label'] = train_data['label'].apply(lambda x: int(x))\n",
    "test_data['label'] = test_data['label'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提取train的Label标签，以备第二层训练的时候使用\n",
    "train_label=pd.DataFrame()\n",
    "train_label['label']=train_data['label']\n",
    "\n",
    "data=pd.concat([train_data,test_data],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========使用到了2种算法========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "\n",
    "lr=LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.08, random_state=1,\n",
    "                            solver='liblinear', max_iter=100,verbose=1)\n",
    "\n",
    "lgb= LGBMClassifier(boosting_type='gbdt', num_leaves=60, max_depth=-1, \n",
    "                         learning_rate=0.05, n_estimators=2000,objective='binary', \n",
    "                         min_split_gain=0,min_child_weight=5, min_child_samples=10, \n",
    "                         subsample=0.8, subsample_freq=1,colsample_bytree=0.8, \n",
    "                         reg_alpha=3, reg_lambda=5, random_state=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========跑def========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049998, 8)\n",
      "(50000, 8)\n",
      "(2049998, 92) (50000, 92) (2099998, 92)\n"
     ]
    }
   ],
   "source": [
    "data=base_data(data)\n",
    "traindf,testdf=get_ctr(data)\n",
    "data=pd.concat([traindf,testdf],axis=0)\n",
    "print(traindf.shape,testdf.shape,data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf=testdf.drop(['label'],axis=1)\n",
    "for fea in testdf.columns:\n",
    "    testdf[fea]=testdf[fea].fillna('-1')\n",
    "    data[fea]=le.fit_transform(data[fea].apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049998, 92) (50000, 92) (2099998, 92)\n"
     ]
    }
   ],
   "source": [
    "traindf=data[:train_data.shape[0]]\n",
    "testdf=data[train_data.shape[0]:]\n",
    "print(traindf.shape,testdf.shape,data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========valdf提取==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valdf=traindf[train_data.shape[0]-1:]\n",
    "print(valdf.shape)\n",
    "valdf.to_csv('../data/valdf.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =========提取结束============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf=testdf.drop(['label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置好X，y，testX以备后面训练lr，lgb使用\n",
    "y=traindf.pop('label').values\n",
    "X=traindf.as_matrix()\n",
    "testX=testdf.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============lightgbm=============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>1.============第一层训练=========<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold=0\n",
      "Training until validation scores don't improve for 100 rounds.\n"
     ]
    }
   ],
   "source": [
    "lgb_all=lgb_fit(lgb,X,y,testX,N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train=lgb_all[0]\n",
    "lgb_train=label_feature(lgb_train,N=10)\n",
    "print(lgb_train.shape)\n",
    "\n",
    "lgb_test=lgb_all[1]\n",
    "lgb_test=label_feature(lgb_test,N=10)\n",
    "print(lgb_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train.to_csv('../data/ensemble/lgb_train1.csv')\n",
    "lgb_test.to_csv('../data/ensemble/lgb_test1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>2.============得到第一层训练后的stacking feature,并再次使用lr训练=========<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacklgb=lgb_all[2]\n",
    "lgbX=lgb_all[3]\n",
    "y=train_label['label'].values\n",
    "\n",
    "lvl_lgb=lr_fit(lr,stacklgb,y,lgbX,N=10)\n",
    "\n",
    "sub_df=lvl_lgb[1]\n",
    "sub_df=label_feature(sub_df,N=10)\n",
    "print(label_proba.shape)  #对应的应该是（50000，N+1）\n",
    "\n",
    "sub_df['label']=sub_df['label'].apply(lambda x:np.where(x>0.37,1,0))\n",
    "print(sub_df.label.value_counts())\n",
    "sub_df['label'].to_csv('../data/BaselineV1_7_lgbstack.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================LR================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>1.============第一层训练=========<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm=MinMaxScaler()\n",
    "X=mm.fit_transform(X)\n",
    "testX=mm.transform(testX)\n",
    "\n",
    "lr_all=lr_fit(clf,X,y,testX,N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train=lr_all[0]\n",
    "lr_train=label_feature(lr_train,N=10)\n",
    "print(lr_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_test=lr_all[1]\n",
    "lr_test=label_feature(lr_test,N=10)\n",
    "print(lr_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train.to_csv('../data/ensemble/lr_train1.csv')\n",
    "lr_test.to_csv('../data/ensemble/lr_test1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>2.============得到第一层训练后的stacking feature,并再次使用lr训练=========<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacklr=lr_all[2]\n",
    "lrX=lr_all[3]\n",
    "y=train_label['label'].values\n",
    "\n",
    "lvl_lr=lr_fit(lr,stacklr,y,lrX,N=10)\n",
    "\n",
    "sub_df=lvl_lr[1]\n",
    "sub_df=label_feature(sub_df,N=10)\n",
    "print(label_proba.shape)  #对应的应该是（50000，N+1）\n",
    "\n",
    "sub_df['label']=sub_df['label'].apply(lambda x:np.where(x>0.37,1,0))\n",
    "print(sub_df.label.value_counts())\n",
    "sub_df['label'].to_csv('../data/BaselineV1_7_lrstack.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>=========第二层：读取model feature======<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train=pd.read_csv('../data/ensemble/lgb_train1.csv')\n",
    "lgb_test=pd.read_csv('../data/ensemble/lgb_test1.csv')\n",
    "\n",
    "lr_train=pd.read_csv('../data/ensemble/lr_train1.csv')\n",
    "lr_test=pd.read_csv('../data/ensemble/lr_test1.csv')\n",
    "\n",
    "ntrain=pd.concat([lgb_train,lr_train],axis=1)\n",
    "ntrain['label']=train_label['label']\n",
    "print(ntrain.shape)\n",
    "print(ntrain.label.value_counts())\n",
    "\n",
    "ntest=pd.concat([lgb_test,lr_test],axis=1)\n",
    "print(ntest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置第二层的X，y，testX\n",
    "y=ntrain.pop('label').values\n",
    "X=ntrain.as_matrix()\n",
    "testX=ntest.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========第二层：用lgb训练=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LGBMClassifier(boosting_type='gbdt', num_leaves=48, max_depth=-1, \n",
    "                         learning_rate=0.05, n_estimators=4000,objective='binary', \n",
    "                         min_split_gain=0,min_child_weight=5, min_child_samples=10, \n",
    "                         subsample=0.8, subsample_freq=1,colsample_bytree=0.8, \n",
    "                         reg_alpha=3, reg_lambda=5, random_state=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_train,ens_test=lgb_fit(clf,X,y,testX,N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_proba=label_feature(ens_test,N=10)\n",
    "print(label_proba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_proba['label']=label_proba['label'].apply(np.where(x>0.37,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_proba['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( /50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_proba['label'].to_csv('../data/BaselineV1_5.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========第二层：用lr训练=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_train,ens_test=lr_fit(lr,X,y,testX,N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_proba=label_feature(ens_test,N=10)\n",
    "print(label_proba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_proba['label']=label_proba['label'].apply(np.where(x>0.37,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_proba['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
